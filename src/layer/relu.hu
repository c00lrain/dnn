#ifndef RELU_HU
#define RELU_HU

// Collaborative threadblock relu forward pass
__device__ void block_relu_forward(float *out, const float *in,
                                   const int size) {
  for (int i = threadIdx.x; i < size; i += blockDim.x) {
    out[i] = in[i] * (in[i] > 0 ? 1 : 0.01);
  }
}

// dE/dx = dE/dy * dy/dx
__device__ void block_relu_backward(float *dx, const float *dy, const float *y,
                                    const int size) {
  for (int i = threadIdx.x; i < size; i += blockDim.x) {
    dx[i] = dy[i] * (y[i] > 0 ? 1 : 0.01);
  }
}

class ReluOp {
public:
  float *x_h;
  float *x_d;
  float *y_h;
  float *y_d;
  float *dy_h;
  float *dy_d;

  ReluOp(const float *hostIn, *deviceIn) : x_h(hostIn), x_d(deviceIn) {
    y_h = nullptr;
    y_d = nullptr;
    dy_h = nullptr;
    dy_d = nullptr;
  }

  void allocate(const size_t size) {

  }
private:

};

#endif